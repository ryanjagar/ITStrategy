---
layout: post
title: "La mobilisation des utilisateurs dans la prestation des services"
ref: user-engagement-in-service-delivery
lang: fr
author: " Elmina Iusifova, en collaboration avec lâ€™Ã©quipe de stratÃ©gie TI"
date: "16-09-2021"
last_modified: "16-09-2021"
excerpt_separator: <!--more-->
---
<!-- markdownlint-disable MD033 -->
<!-- the below cSpell statement says to ignore any text between HTML tags. e.g., it will ignore "th rowspan='2'" in this string: <th rowspan='2'> -->
<!-- cSpell:ignoreRegExp /\<[^\>]+\>/ -->
<!-- The img + em {} stylecheet selector is a hack to add caption to an image in markdown without using plugin: https://stackoverflow.com/questions/19331362/using-an-image-caption-in-markdown-jekyll -->

<style>
table, th, td {
  border: 1px solid black;
}

th {
  background-color: #ccccff;
}

img + em { display: inline-block; }
</style>

Pourquoi crÃ©ons-nous des services?
Plusieurs rÃ©ponses sont possibles, mais ma prÃ©fÃ©rÃ©e est la suivante :

> Offrir aux clients une solution qui leur coÃ»te moins cher que le coÃ»t du problÃ¨me.
<!--more-->

Les services fonctionnent lorsque les gens les utilisent et s'ils fonctionnent bien, un plus grand nombre de personnes les utilisent.
En gÃ©nÃ©ral, les utilisateurs ne rÃ©alisent pas quand la prestation des services change, parce quâ€™ils se sont habituÃ©s aux amÃ©liorations mises en place et se sont adaptÃ©s Ã  la nouvelle norme presque immÃ©diatement.
Par contre, ce qui nâ€™a *pas* changÃ©, câ€™est que lorsquâ€™ils *interagissent* avec un service, ils veulent une expÃ©rience utilisateur **exceptionnelle**.

Les [Normes relatives au numÃ©rique du gouvernement Canada](https://www.canada.ca/fr/gouvernement/systeme/gouvernement-numerique/normes-numeriques-gouvernement-canada.html) reposent sur lâ€™objectif suivantÂ : fournir aux Canadiens des services publics Â«Â faciles Ã  utiliserÂ Â».
Pour concevoir des produits Â«Â axÃ©s sur lâ€™utilisateurÂ Â», l'utilisateur doit participer Ã  tous les aspects de la recherche afin dâ€™optimiser le temps et les efforts consacrÃ©s Ã  la comprÃ©hension de ses besoins et de ses problÃ¨mes.

Nous devons concevoir de meilleurs produits pour les citoyens et les collÃ¨gues de la fonction publique.
*Pourquoi?* Parce que Â«Â nousÂ Â» le rÃ©clamons.
Parce qu'une relation durable et bien structurÃ©e est l'ingrÃ©dient secret pour rendre les utilisateurs heureux.

### CrÃ©er des personas

Dans lâ€™Ã©quipe de stratÃ©gie TI, nous avons conÃ§u et mis en Å“uvre plusieurs produits et, heureusement, nous avons eu lâ€™occasion de faire participer les utilisateurs tout au long du processus de conception et de tester nos prototypes avant le lancement.
Notre premiÃ¨re Ã©tape cherchait Ã  en savoir le plus possible sur les utilisateursÂ : leur contexte, objectifs et obstacles afin dâ€™Ã©clairer notre orientation gÃ©nÃ©rale.
Nous avons crÃ©Ã© des personas pour nous aider Ã  connaÃ®tre nos utilisateurs, leur comportement, leurs objectifs et leurs frustrations, ainsi qu'Ã  comprendre pour qui nous concevons un produit et si celui-ci rÃ©pond aux besoins de notre public cible.

Câ€™est ce qui sâ€™est produit pendant le sprint de conception de lâ€™[outil dâ€™auto-Ã©valuation DevOps](https://sara-sabr.github.io/ITStrategy/devops-self-assessment.html).
Ã€ partir de recherches, nous avons crÃ©Ã© des personnages fictifs pour nous aider Ã  comprendre lâ€™utilisateur pour lequel nous concevons.
Nous avons dÃ©couvert diffÃ©rents types dâ€™utilisateurs avec leurs modÃ¨les de comportement, objectifs, compÃ©tences, attitudes et antÃ©cÃ©dents, ainsi que lâ€™environnement dans lequel ils Ã©voluent. Cela nous a permis de connaÃ®tre les Ã©lÃ©ments exigeant notre attention et de nous amÃ©liorer pendant la conception de notre application.
Le principal utilisateur de lâ€™outil est un fonctionnaire de la DGIIT qui souhaite continuellement s'amÃ©liorer et soutenir les efforts de ses pairs.
En comprenant les attentes, les prÃ©occupations et les motivations de nos utilisateurs cibles, nous avons mis au point une solution axÃ©e sur la conception.
Lorsque lâ€™on conÃ§oit pour un fonctionnaire alors que lâ€™on est soi-mÃªme un fonctionnaire, il est trÃ¨s facile de crÃ©er un produit autorÃ©fÃ©rentiel comme s'il nous Ã©tait uniquement destinÃ©. Or, le public cible peut Ãªtre trÃ¨s diffÃ©rent de nous.
Nous avons Ã©galement crÃ©Ã© une maquette qui a rÃ©cemment Ã©tÃ© prÃ©sentÃ©e Ã  une vÃ©ritable Ã©quipe dâ€™utilisateurs afin de recueillir des commentaires et dâ€™apporter dâ€™autres amÃ©liorations.

En pensant aux besoins de notre persona dâ€™utilisateur final, nous avons tentÃ© de faÃ§onner la stratÃ©gie de produits et de crÃ©er la meilleure maquette pour *lui/elle*.
Fait Ã  noter, mÃªme si les personas dâ€™utilisateur nous ont aidÃ©s Ã  prioriser les fonctions, ce nâ€™Ã©tait pas le seul outil utilisÃ© pour Ã©tablir les prioritÃ©s.
Nous recueillions constamment les commentaires des intervenants afin de maintenir un juste Ã©quilibre entre les besoins de lâ€™organisation et ceux des utilisateurs, afin de concevoir une solution qui satisferait les deux.
Avec les commentaires que nous avons reÃ§us, nous avons tentÃ© de raffiner lâ€™expÃ©rience globale pour lâ€™utilisateur.

### AccessibilitÃ© et multilinguisme

Lâ€™accessibilitÃ© est une partie importante de la conception des services au gouvernement, et elle doit Ãªtre prise en compte tout au long du processus.
Selon la [Loi canadienne sur lâ€™accessibilitÃ©](https://www.canada.ca/fr/emploi-developpement-social/programmes/canada-accessible.html), la prestation des programmes et des services est lâ€™un des principaux domaines sur lequel le gouvernement du Canada doit cibler ses efforts.
Un autre aspect important Ã  considÃ©rer au gouvernement est l'exigence de servir les citoyens dans la langue officielle de leur choix.
Afin de respecter les prÃ©fÃ©rences du public canadien en matiÃ¨re de langues officielles, nous devons concevoir des services bilingues (voir [Langues officielles dans les communications et le service au public](https://www.canada.ca/fr/secretariat-conseil-tresor/services/valeurs-ethique/langues-officielles/services-public.html)).
Afin dâ€™obtenir des rÃ©sultats de meilleure qualitÃ©, la conception de lâ€™interface utilisateur de nos services doit respecter le cadre de la [BoÃ®te Ã  outils de lâ€™expÃ©rience Web](https://wet-boew.github.io/wet-boew/index-fr.html) dirigÃ© par le gouvernement du Canada.
Il sâ€™agit dâ€™un cadre libre collaboratif qui porte sur lâ€™accessibilitÃ©, la convivialitÃ© et les aspects multilingues en fournissant des modÃ¨les rÃ©utilisables qui nous aident Ã  crÃ©er un premier prototype de modÃ¨le/d'Ã©chantillon pour tester des hypothÃ¨ses.

### Essais de convivialitÃ©

Pour comprendre comment les vÃ©ritables utilisateurs interagissent avec nos applications, nous avons mis lâ€™accent sur la crÃ©ation dâ€™un plan dâ€™essai de convivialitÃ©.
Ce plan sâ€™apparente Ã  un plan directeur qui contient des renseignements comme la mÃ©thodologie (une brÃ¨ve explication du dÃ©roulement de la mise Ã  lâ€™essai), le script de lâ€™animateur (un script quâ€™un animateur suit et qui comprend des instructions, des sujets et des questions qui seront utilisÃ©s Ã  chaque sÃ©ance dâ€™essai, afin dâ€™assurer lâ€™uniformitÃ©), des cas de tÃ¢ches (un rÃ©sumÃ© de lâ€™expÃ©rience que pourraient vivre les utilisateurs typiques en utilisant le produit) et le calendrier des participants.

Pour Ã©valuer le rendement de notre conception et de nos produits, nous avons effectuÃ© des essais de convivialitÃ© auprÃ¨s de plusieurs utilisateurs.
Il sâ€™agit dâ€™une dÃ©marche dans laquelle les rÃ©sultats ne sont pas connus Ã  lâ€™avance et qui peut exiger du temps et susciter de lâ€™ambiguÃ¯tÃ©.
Mais cet exercice est AMUSANT! ğŸ™‚
Lâ€™objectif principal de ce processus est dâ€™Ã©valuer les idÃ©es et les solutions que nous avons trouvÃ©es et de dÃ©terminer ce qui fonctionne et ce qui ne fonctionne pas.
Nous avons testÃ© notre application et Ã©coutÃ© nos utilisateurs pour les comprendre.
**Ã‰couter les utilisateurs est une chose difficile.
Souvent, les utilisateurs ne savent pas ce quâ€™ils veulent, et mÃªme sâ€™ils le savent, la communication risque dâ€™Ãªtre mal interprÃ©tÃ©e par lâ€™utilisateur et lâ€™animateur.**
Pour recevoir des commentaires utiles des utilisateurs et de l'information exacte en premier lieu, nous devions dâ€™abord nous assurer, lors de la prÃ©paration du scÃ©nario de lâ€™animateur, de tenir compte prÃ©cisÃ©ment des Ã©lÃ©ments Ã  tester, puis de le faire comme convenu.
Dans ce cas, il y avait un grand risque que le script oriente lâ€™utilisateur pour quâ€™il donne une rÃ©troaction particuliÃ¨re qui ne serait pas objective.
Pour concevoir la meilleure expÃ©rience utilisateur, nous avons donc portÃ© attention principalement Ã  ce que les utilisateurs font, et non Ã  ce quâ€™ils disent, afin dâ€™Ã©viter les affirmations qui ne sont pas fiables.

Dans le cas de lâ€™[outil dâ€™autoÃ©valuation DevOps](https://sara-sabr.github.io/auto-evaluation-devops-self-assessment/#/), nous avons mis Ã  lâ€™essai les problÃ¨mes de convivialitÃ© du site WebÂ : problÃ¨mes de mise en page, manque de rÃ©troaction, terminologie dÃ©routante, fonctionnalitÃ© manquante (si lâ€™utilisateur ne peut pas effectuer une tÃ¢che particuliÃ¨re en raison dâ€™un Ã©lÃ©ment manquant dans l'interface), navigation manquante (si lâ€™utilisateur est bloquÃ© sur un Ã©cran pendant lâ€™essai) et contenu d'Ã©crans particuliers.
Au cours des essais, nous demandions Ã©galement aux utilisateurs des commentaires gÃ©nÃ©raux sur lâ€™utilitÃ© de lâ€™application et la faÃ§on dont elle peut Ãªtre amÃ©liorÃ©e.
Nous nous sommes assurÃ©s que les utilisateurs connaissent le but du prototype et de lâ€™essai.
Toutefois, nous avons Ã©vitÃ© dâ€™expliquer trop en dÃ©tail le fonctionnement du prototype, ou la faÃ§on dont il devrait rÃ©soudre les problÃ¨mes des utilisateurs.
Nous avons laissÃ© lâ€™expÃ©rience dâ€™utilisation du prototype par lâ€™utilisateur parler dâ€™elle-mÃªme et observÃ© les rÃ©actions de celui-ci.
Nous avons rassurÃ© les participants quâ€™au cours de la sÃ©ance, nous testons le prototype et non lâ€™utilisateur. Nous avons expliquÃ© quâ€™il nâ€™y a pas de bonnes ou de mauvaises rÃ©ponses aux questions posÃ©es et que tout comportement de leur part nous aidera Ã  combler les lacunes que nous avons manquÃ©es lors de la conception de lâ€™application.
Nous avons prÃ©sentÃ© les tÃ¢ches une Ã  la fois, et avons invitÃ© les participants Ã  Â«Â rÃ©flÃ©chir Ã  haute voixÂ Â», et notamment exprimer leurs prÃ©occupations, opinions et commentaires.
Nous avons demandÃ© aux utilisateurs de parler de leurs expÃ©riences, ce qui a Ã©tÃ© crucial lors de conception de notre produit.

Les tests de convivialitÃ© de lâ€™outil dâ€™auto-Ã©valuation DevOps pendant la pandÃ©mie de COVID-19 ont Ã©tÃ© effectuÃ©s Ã  distance.
Nous avons alors perdu lâ€™avantage du contact en personne, mais personnellement nous avons trouvÃ© que les essais Ã  distance Ã©taient tout aussi efficaces que les essais traditionnels.
Les essais en ligne Ã  distance donnent accÃ¨s Ã  un plus grand bassin de testeurs potentiels, rÃ©duisent le temps de dÃ©placement et donnent plus de souplesse aux participants.
Et surtout, les gens accomplissent des tÃ¢ches Ã  la maison (c.-Ã -d. un environnement oÃ¹ ils sont confortables), oÃ¹ ils utiliseront nos produits finaux.
Par consÃ©quent, les dÃ©couvertes sur la convivialitÃ© que nous avons tirÃ©es de lâ€™essai Ã©taient plus proches du monde rÃ©el.

### Collecte de commentaires et mise en Å“uvre

Pendant la collecte de commentaires, il est trÃ¨s important de ne pas perturber lâ€™interaction de lâ€™utilisateur avec le prototype.
Nous devions trouver un moyen de recueillir les commentaires dâ€™une maniÃ¨re qui nous permettait dâ€™observer sans entraves ce qui se passait.
Pour ce faire, avec la permission de lâ€™utilisateur, nous avons utilisÃ© la fonction dâ€™enregistrement dâ€™Ã©cran dans MS Teams et avons enregistrÃ© chaque session.
Câ€™Ã©tait le moyen le plus facile de saisir les pensÃ©es et les gestes de lâ€™utilisateur pendant la session dâ€™essai.
La vidÃ©o numÃ©rique est un rÃ©sultat trÃ¨s pratique des sessions dâ€™essai de convivialitÃ© qui montre clairement lâ€™interaction de lâ€™utilisateur avec les Ã©lÃ©ments Ã  lâ€™Ã©cran.
Nous avons discutÃ© et mis Ã  lâ€™essai notre produit auprÃ¨s dâ€™environ six ou sept utilisateurs, ce qui Ã©tait suffisant pour comprendre ce qui doit Ãªtre amÃ©liorÃ© et examinÃ© avant dâ€™apporter des changements au produit.

Pendant les essais de convivialitÃ©, nous avons reÃ§u une vaste quantitÃ© de commentaires des utilisateurs.
Chaque utilisateur est unique, et peut donc fournir divers types de renseignements utiles.
Une tÃ¢che dÃ©licate consiste Ã  faire la distinction entre les prÃ©fÃ©rences/dÃ©sirs des utilisateurs et leurs besoins.
La mise en Å“uvre accrue des dÃ©sirs de lâ€™utilisateur peut tellement compliquer le produit et lâ€™alourdir que mÃªme certains utilisateurs, qui ont Ã©tÃ© invitÃ©s Ã  utiliser les fonctionnalitÃ©s, prÃ©fÃ©reraient ne pas utiliser le produit final.
Il est donc trÃ¨s important de faire une distinction entre les dÃ©sirs et les besoins, et de ne pas Ã©valuer trop rapidement chaque point de rÃ©troaction.
Certaines suggestions pourraient ne pas Ãªtre avantageuses pour le produit. Donc, par consÃ©quent, nous devions Ãªtre stratÃ©giques Ã  dÃ©terminer quels commentaires mÃ©ritaient un suivi.

Pour utiliser les rÃ©sultats, il importe de ne pas exagÃ©rer ou ajouter quelque chose Ã  ce qui a Ã©tÃ© vu ou entendu.
Afin de saisir les rÃ©sultats avec exactitude, nous avons mis en correspondance les commentaires particuliers avec nos questions de recherche, dÃ©terminÃ© quelles questions ont obtenu une rÃ©ponse ou non, de mÃªme que les nouvelles questions qui ont Ã©tÃ© posÃ©es.
Pour ce faire, nous avons Ã©tabli lâ€™ordre de prioritÃ© des commentaires reÃ§us des utilisateurs dans un carnet dâ€™idÃ©es avant chaque rÃ©union de planification de lâ€™itÃ©ration, pour nous assurer que lâ€™ordre de prioritÃ© Ã©tait pertinent.

### Lâ€™expÃ©rience utilisateur ne se termine jamais

Lâ€™expÃ©rience utilisateur ne sâ€™arrÃªte pas ici.
Tous les efforts consacrÃ©s Ã  la planification, Ã  la recherche et Ã  la crÃ©ation du produit nous ont permis de passer Ã  la phase de lancement.
Mais aussi, suite au lancement, nous devons consacrer du temps Ã  la production pour nous assurer que nous crÃ©ons des produits qui sont utiles aux utilisateurs.
Donc aprÃ¨s le lancement, la phase dâ€™optimisation commence.
Une fois que les utilisateurs auront mis la main sur le produit, nous pourrions constater â€“ grÃ¢ce aux donnÃ©es et au comportement des utilisateurs â€“ que bon nombre de nos hypothÃ¨ses initiales sont fausses ou que les utilisateurs utilisent notre produit de diffÃ©rentes faÃ§ons.
Nous continuons de surveiller lâ€™expÃ©rience utilisateur de chacun de nos produits en demandant aux utilisateurs de nous faire part de leurs commentaires.
Câ€™est alors que commence une tout autre phase de lâ€™expÃ©rience utilisateur.

*Ai-je mentionnÃ© que lâ€™expÃ©rience utilisateur est un processus sans fin?*